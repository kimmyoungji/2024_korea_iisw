{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ded74f-33a3-4885-87aa-c2016e1ddac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Preprocessing : 전처리\n",
    "Tokenizing => Tokens = {음절, 어절, 단어, 형태소, 어근, 접사, 어간, 어미, 구 ... ngram, 품사}\n",
    "           => 왜? => 좋은 feature들을 찾으려고. => 좋은 토큰을 뽑아야지만, 좋은 모델이 만들어진다.\n",
    "\n",
    "zip's law => 빈도의 순으로 나열 = 순위의 역순이랑 동일, 가장 많이 나온 단어는 그 다음 단어의 두배\n",
    "             고빈도단어(문장부호, 접사, 조사.... -> 의미 파악시 별로 안 중요함); 상위 n개의 단어가 대부분 차지\n",
    "             저빈도단어(고유명사, 신조어,비속어,오탈자); 토큰 후보들 중 대부분을 차지하는 너무 많음\n",
    "Heaps law =>  문서에 나타난 고유한 단어들은 전체 단어의 수와 일전한 관계\n",
    "\n",
    "tokenizing 기법:\n",
    "NLTK -> sent_tokenize : 문장 단위로 쪼갤 때 사용한다. , word_tokenize => regex_tokenize, Tweettokenize\n",
    "한글  -> Morpheme analyser, POS, nouns .... 품사표(tagset)\n",
    "        => key 못 찾음; Out of Vocabulary (OOV) =>unknown 토은 저장하면된데, 이제 근간이 되는 데이커기때문에...\n",
    "\n",
    "Entropy, Perplexity(Cohestipon) => 조건부확률\n",
    "Stemming. (Stem, 어간); 어간+어미; 있다| 있었다| 있었고 | 있었으며 .. \n",
    "Lemmatization(Lemma) 페제어 추출; 어근/원형, 날다 + 나/는 ... => 날/눈,,,,,\n",
    "                           is  was be ... -:\n",
    "\n",
    "SPM - WPM - BPE(*)   => 워드피스모델: 단어조각\n",
    "; Sententce-picec Model(문장; 분절 띄어쓰기)=> 0\n",
    "      ; Word-Piece-Model(어절;분절)\n",
    "            ; Byte Pair Encoding 방법 (*) \n",
    "\n",
    "Normaliazion\n",
    "대소문자, 약어(LA, losangeles), Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57236ca2-11bf-4bfb-886b-a1c676b3e7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cb1f0-781c-4ce4-bdbe-9fc41ef89497",
   "metadata": {},
   "outputs": [],
   "source": [
    "ma = Hannanum()\n",
    "data='''2022년 말 GTP-3.5 기반의 챗GPT를 공개한 오픈AI는 불과 4개월 만인 지난해 3월 GPT-4를 선보였다. 매개변수는 공개하지 않았지만 1750억개인 GPT-3.5보다 증가했고 인식 가능한 명령어도 GPT-3.5가 문자만 가능했다면 GPT-4는 문자는 물론 이미지까지 포함했다.\n",
    "\n",
    "인식 가능한 글 길이도 단어 약 3000개에서 2만5000여 개로 늘어났다. 오픈AI는 GPT-3.5의 미국 변호사 시험 성적이 하위 10%였다면 GPT-4는 상위 10%를 기록하면서 보다 인간다워졌다고 밝혔다. 그리고 지난해 11월에는 멀티모달리티 기능을 강화한 'GPT-4 터보'를 선보인 바 있다.\n",
    "\n",
    "업계는 오픈AI가 공개를 앞둔 GPT-5가 범용 인공지능(AGI)에 얼마나 가까워졌을지 주목하고 있다. 아직 완벽한 AGI 구현은 어렵겠지만 GPT-5가 AGI를 개발하는 데 징검다리 역할을 할 수 있기 때문이다.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445ca189-0d21-4594-b92a-b103b4542e9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ma.nouns(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f57b5-7ad0-42c1-b416-11e27c64663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
    "\n",
    "ma = [Hannanum(), Kkma(), Komoran(), Okt()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abeea8-759b-474f-b62b-11a13ad5c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in ma:\n",
    "    print(m.pos('하늘을 나는 새'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e20dd-f239-4d3a-a754-e5f7e375a293",
   "metadata": {},
   "source": [
    "# 띄어쓰기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ecfc1-6fac-4732-824f-19bda83c275e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e3eeab-2b63-451a-9b46-e7752e6008bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스 수집기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8781f966-3ff4-49ee-812c-f95799a99f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests.compat import urljoin\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "urls = ['https://news.naver.com']\n",
    "seens = []\n",
    "path = './news'\n",
    "\n",
    "while urls:\n",
    "    url = urls.pop(0)\n",
    "    \n",
    "    resp = get(url)\n",
    "    seens.append(url)\n",
    "\n",
    "    if not re.search(r'text\\/html', resp.headers['content-type']):\n",
    "        continue\n",
    "        \n",
    "    dom = BeautifulSoup(resp.text, 'html.parser')\n",
    "    \n",
    "    # 1번 뉴스 메뉴\n",
    "    for a in dom.select('.Nlnb_menu_list > li > a[href]')[1:7]:\n",
    "        nurl = urljoin(url, a.attrs['href'])\n",
    "        if nurl not in urls and nurl not in seens:\n",
    "            urls.append(nurl)\n",
    "    # 헤드라인\n",
    "    for a in dom.select('[id^=\"_SECTION_HEADLINE_LIST\"] .sa_text_title[href]'):\n",
    "        nurl = urljoin(url, a.attrs['href'])\n",
    "        if nurl not in urls and nurl not in seens:\n",
    "            urls.append(nurl)\n",
    "\n",
    "    # 3번 - 뉴스본문 # 원래는 있는지 없는지 봐야함\n",
    "    c = dom.select_one('#contents')  \n",
    "    if c: \n",
    "        file = re.search(r'(\\d{8,})$',url).group(1)\n",
    "        with open(f'{path}{file}.txt', 'w', encoding='utf8') as f:\n",
    "            f.write(c.get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f0b016f-21a5-413c-bb9d-845f3258fee0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Untitled Folder',\n",
       " './0325.ipynb',\n",
       " './0327.ipynb',\n",
       " './0326.ipynb',\n",
       " './news',\n",
       " './.ipynb_checkpoints']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "def fileids(path):\n",
    "    return list(map(lambda f:path + ('' if path[-1] == '/' else '/')+f, listdir(path)))\n",
    "    \n",
    "fileids('./')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087070d6-77b6-4b33-9661-ed5b3b44e6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "842e1971-cc3e-4790-9a59-147314fd3384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "corpus = list()\n",
    "for file in fileids('news'):\n",
    "    with open(fileids('./news')[0], 'r', encoding='utf8') as f:\n",
    "        d = f.read()\n",
    "        corpus.append(  re.sub( r'\\sCopyright.+', '', re.sub( r'^\\s+|\\s+$', '', re.sub( r'\\s+', ' ', re.sub(r'\\x00-\\xff', '', d))))  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebb73c98-2a68-4294-a227-0142d0a75d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.text import Text\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer  # 어간 추출, 어간: 단어의 줄기\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5bba698-a9a9-462d-a271-44e61e4da227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('play', 'play', 'play', 'wa')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PorterStemmer().stem('play'),\\\n",
    "PorterStemmer().stem('played'),\\\n",
    "PorterStemmer().stem('playing'),\\\n",
    "PorterStemmer().stem('was')  # ==> 이렇게 오류가 나는 지점 때문에 lemma도 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "380df739-f437-4749-a565-0803b17f7536",
   "metadata": {},
   "outputs": [],
   "source": [
    "tObj = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a293d-fe5c-43cd-bf2f-24245d3f57de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Hannanum, Kkma, Komoran, Okt\n",
    "\n",
    "ma = [Hannanum(), Kkma(), Komoran(), Okt()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8128d-e7fb-4560-81b4-17ce154788b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in corpus:\n",
    "    if len(tObj) == 0:\n",
    "        tObj.append(Text(word_tokenize(d)).vocab)\n",
    "    else:\n",
    "        tObj.append(tObj[-1] + Text(word_tokenize(d)).vocab())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc052969-6175-412d-bfd7-1504c15bda2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tObj[-1].N(), tObj[-1].B()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa5caf0-3b24-4a9e-b307-f063fef3e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kkmtObj = list()\n",
    "\n",
    "for d in corpus:\n",
    "    if len(kkmtObj) == 0:\n",
    "        kkmtObj.append(Text(ma[1].morphs(d)).vocab())\n",
    "    else:\n",
    "        kkmtObj.append(kkmObj[-1] + Text(ma[1].morphs(d)).vocab())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf18f98-3f3c-4c66-8aaf-8d5e5e629ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zips laws\n",
    "n = 50\n",
    "plt.plot([1/i for i in range(1,n+1)], c='k')\n",
    "plt.plot([r[1]/tObj[-1].get(tObj[-1].max()) for r in tObj[-1].most_common(n)], c='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6981a2e8-9250-40c4-8a03-68ccdee66973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# heaps laws\n",
    "k = 12\n",
    "b = .48\n",
    "plt.plot([k.B() for k in kkmtObj], c='k')\n",
    "plt.plot([12*k.N() for k in kkmtObj], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c6663a9-d727-4139-8f7f-b1036e9b4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngram(s,n=2,t=True):  #음절이냐, 어절이냐의 차이로 해본다.  # t=True; 어절  t=False; 음절\n",
    "    result  = []\n",
    "    if not t:\n",
    "        s = list(s)\n",
    "\n",
    "    for i in range(len(s)-(n-1)):\n",
    "        result.append(tuple(s[i:i+n]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95aac099-882b-426b-9809-a91764e1a387",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ngram() missing 1 required positional argument: 's'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gram \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[43mngram\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m}\n",
      "\u001b[0;31mTypeError\u001b[0m: ngram() missing 1 required positional argument: 's'"
     ]
    }
   ],
   "source": [
    "gram = {'1': ngram()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c5ff3b-67b0-4905-91ba-9542b55268eb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m gram3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[1;32m      4\u001b[0m gram4 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcorpus\u001b[49m:\n\u001b[1;32m      7\u001b[0m     gram1\u001b[38;5;241m.\u001b[39mexend(ngram(c,t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m      8\u001b[0m     gram2\u001b[38;5;241m.\u001b[39mexend(ngram(c,t\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "gram1 = list()\n",
    "gram2 = list()\n",
    "gram3 = list()\n",
    "gram4 = list()\n",
    "\n",
    "for c in corpus:\n",
    "    gram1.exend(ngram(c,t=False))\n",
    "    gram2.exend(ngram(c,t=False))\n",
    "    gram3.exend(ngram(c,t=False))\n",
    "    gram4.exend(ngram(c,t=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2048b6f3-f7a8-4fb3-ad4b-303f26a7902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc3d6d90-0100-4ec7-8a9f-abc1447b32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = Counter(gram1)\n",
    "c2 = Counter(gram2)\n",
    "c3 = Counter(gram3)\n",
    "c4 = Counter(gram4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "188f03e6-e650-4d3b-a26b-a2ab9f7e3401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2009b86-6fbd-49da-ae23-9ac731ff82f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mplot([\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39mi \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,n\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([i[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(c1\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m c1\u001b[38;5;241m.\u001b[39mmost_common(n)], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mk\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot([i[\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(c2\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m c2\u001b[38;5;241m.\u001b[39mmost_common(n)], c\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "n = 50\n",
    "plt.plot([1/i for i in range(1,n+1)], c='k')\n",
    "plt.plot([i[1]/max(c1.values()) for i in c1.most_common(n)], c='k')\n",
    "plt.plot([i[2]/max(c2.values()) for i in c2.most_common(n)], c='r')\n",
    "plt.plot([i[3]/max(c3.values()) for i in c3.most_common(n)], c='g')\n",
    "plt.plot([i[4]/max(c4.values()) for i in c4.most_common(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0fd5a58d-7224-400e-9d3b-b38b4a75d334",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2043153614.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[29], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    re.sub(r'\\s', '', sent_tokenize(corpus([0])[0])\u001b[0m\n\u001b[0m                                                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "re.sub(r'\\s', '', sent_tokenize(corpus([0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bb8a078a-d4dc-4114-bb3a-a98f1d94cf29",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fileids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfileids\u001b[49m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnews\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fileids' is not defined"
     ]
    }
   ],
   "source": [
    "fileids('news')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ed44c7-a10c-48d1-90d8-6f1402bf74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = re.sub(r'\\s',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6445583c-6df1-4346-8665-bf44f7bfa9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcorpus\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21aae30f-f732-4fc4-87a7-6a38fb2a4e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (1918617479.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[32], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    findKey(gram2),'가')\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "def findkey(gram, key):\n",
    "    k = tuple(key)\n",
    "    return filter(lambdal g:g[:len(k)], )\n",
    "\n",
    "findKey(gram2),'가')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7457194-4ebb-4994-8ed1-887008833795",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
